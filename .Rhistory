#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
TotRmsAbvGrd)%>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtUnfSF,TotalBsmtSF,X1stFlrSF,X2ndFlrSF,LowQualFinSF,GrLivArea) %>%
ggpairs()
#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
TotRmsAbvGrd)%>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
TotRmsAbvGrd)%>%
ggpairs()
#The only variable seem to have good correlation with lSalePrice is FullBath,TotRmsAbvGrd.
#???If we should change BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr to factors???
#Keep going
amesHouse %>% dplyr::select(SalePrice,GarageYrBlt,GarageCars,GarageArea) %>% ggpairs()
amesHouse %>% dplyr::select(lSalePrice,GarageYrBlt,GarageCars,GarageArea) %>% ggpairs()
#The above variables all seem to have a good linear correlation with lSalePrice
#Keep going
amesHouse %>% dplyr::select(SalePrice,WoodDeckSF,OpenPorchSF,EnclosedPorch,X3SsnPorch,ScreenPorch,MiscVal)%>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,WoodDeckSF,OpenPorchSF,EnclosedPorch,X3SsnPorch,ScreenPorch,MiscVal)%>%
ggpairs()
#Loading libraries needed
library(tidyverse)
library(ggplot2)
#Loading in Employee data
employeeData = read.csv("/Users/mingyang/Desktop/SMU/DoingDS_Fall2020/CaseStudy2DDS/CaseStudy2-data.csv",header = TRUE)
summary(employeeData)
#See which column has only unique value
sapply(employeeData,function(col) length(unique(col)))
#Delete column that has only one unique value
to.be.deleted = which(sapply(employeeData,function(col) length(unique(col))==1))
employeeData = employeeData[,-to.be.deleted]
#Convert some values into factors
cols.to.factor = c("Attrition","BusinessTravel","Department","EducationField","EnvironmentSatisfaction",
"Gender","JobInvolvement","JobLevel","JobRole","JobSatisfaction","MaritalStatus","NumCompaniesWorked",
"OverTime","PerformanceRating","RelationshipSatisfaction","StockOptionLevel","TrainingTimesLastYear",
"WorkLifeBalance")
employeeData[cols.to.factor] = lapply(employeeData[cols.to.factor],factor)
#Load in libraries
library(lattice)
library(caret)
library(mlbench)
#prepare training scheme
control = trainControl(method="repeatedcv", number=10, repeats=3)
#train the model
model = train(Attrition~.,data=employeeData,method="lvq",preProcess="scale", trControl=control)
#estimate variable importance
importance = varImp(model,scale=FALSE)
#summarize importance
print(importance)
#plot importance
plot(importance)
#Load NB libraries
library(e1071)
#select variables decided to predict Attrition
data.nb = employeeData %>% select(Attrition, OverTime, MonthlyIncome, TotalWorkingYears, YearsAtCompany, StockOptionLevel, MaritalStatus, JobLevel, YearsInCurrentRole, YearsWithCurrManager, Age, JobInvolvement, JobSatisfaction, JobRole, Department,Education, WorkLifeBalance, EnvironmentSatisfaction)
set.seed(12)
splitPercent = 0.80
trainIndex = sample(1:dim(data.nb)[1],round(splitPercent * dim(data.nb)[1]))
train.nb = data.nb[trainIndex,]
test.nb = data.nb[-trainIndex,]
model.nb = naiveBayes(Attrition~.,data=train.nb, laplace = 1)
predict.nb = predict(model.nb,test.nb)
table(predict.nb,test.nb$Attrition)
confusionMatrix(predict.nb,test.nb$Attrition)
#Load library to run stepwise regression method to choose an optimal simple model
library(MASS)
#Build the model with internel verfication
set.seed(24)
train.control <- trainControl(method = "cv", number = 10)
step.model = train(MonthlyIncome~., data=employeeData,
method="lmStepAIC",
trControl = train.control,
trace=FALSE)
#Model Accuracy
step.model$results
step.model$finalModel
summary(step.model$finalModel)
?sd
?pt
pt(0.95,49)
qt(0.95,49)
?qt
qt(0.975,473.85)
qnorm(0.975,13)
?qnorm
qnorm(0.975,0,1)
?pf
pt(1.06,1,280)
pt(5,1,280)
pf(1.06,1,280)
1- pf(1.06,1,280)
?pt
pt(2.84,14)
1-pt(2.84,14)
1-2*pt(2.84,14)
(1-pt(2.84,14))*2
qnorm(2.84,0,1)
?qnorm
qnorm(2.84)
pnorm(2.84)
1- pnorm(2.84)
2^(1.249-2.594*0.031)
pf(1.06,1,280)
qt(0.95,1000000000)
qnorm(0.95)
qt(0.95,100)
qt(0.95,30)
qt(0.025,30)
qt(0.025,30)
qnorm(0.025,30)
qnorm(0.025)
qt(0.025,100)
qt(0.025,1000000)
qt(0.025,10000000000)
qt(0.45,1000000000000)
qnorm(0.45)
qnorm(0.5)
qt(0.5,1000000000000)
qnorm(0.6)
qt(0.6,1000)
qt(0.6,100)
exp(0.1975)
9.381-8.667
0.714/9
0.079/0.619
pf(0.128,9,14)
1-pf(0.128,9,14)
1.99979-0.001126
0.0998499+0.0102828
1.99979-0.0001084
0.0998499+0.0303267
exp(1.999789181)
Exp(-0.001083732)
exp(-0.001083732)
exp(0.03032665)
231-7
?qt
qt(0.995,224)
0.200127253+0.00013768*2.598
0.200127253-0.00013768*2.598
qt(0.975,224)
1.998664+0.1101327*9.4+0.2001273*2
exp(3.424166)
1.998664+0.1101327*9.4+0.2001273*3
exp(3.634293)
exp(3.627926)
exp(3.640658)
0.010282784-0.030326651
(4+9-8.2)*10^08
sqrt(4.8*10^(-8))
qt(0.975,224)
-0.02004387+1.97*0.000219
-0.02004387-1.97*0.000219
0.714/5
9.381-9.667
9.381-8.667
0.1428/0.619
1-pf(0.231,5,14)
library(tidyverse)
library(ggplot2)
library(GGally)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Directly import cleaned dataset and start from here
CarData = read.csv("CleanedCarData.csv")
###################################################################################
# Restrict prediction range to over cars under 1 million... To improve precision###
###################################################################################
CarData = CarData %>% filter(MSRP < 1000000)
# Convert factor variables
variables.to.factor = c("Make","Model","EngineFuelType","TransmissionType","DrivenWheels","MarketCategory","VehicleSize","VehicleStyle","Crossover","Diesel","Exotic","Luxury","HighPerformance","FactoryTuner","Performance","FlexFuel","Hatchback","Hybrid","N_A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)
summary(CarData)
# Plot agsint numeric variables
# CarData %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity) %>% ggpairs()
CarData = CarData[,-10] #delete MarketCategory
# Try different way of sampling by Models
######### Try Something else to split data ############
# First 836 are Models that only have 5 observations or less - deleted 6 card over 1 million dollars
ModelList = CarData%>% group_by(Model) %>% mutate(ModelCount = n()) %>% arrange(ModelCount)
#arrange(ModelList,desc(count))%>%print(n = Inf)
# Can only split train/test/validate set on Models that has 6 observations or more
ModelList = ModelList[,-27]
Not.Able.To.Split = ModelList[(1:836),]
Able.To.Split = ModelList[-(1:836),]
# Split Train, test, validate based on able to Train Data...
set.seed(111)
validate.set.index<-sample(1:dim(Able.To.Split)[1],1191,replace=F)
validate = Able.To.Split[validate.set.index,]
remains1 = Able.To.Split[-validate.set.index,]
set.seed(112)
test.index = sample(1:dim(remains1)[1],1191,replace=F)
test = remains1[test.index,]
train = remains1[-test.index,]
# Joining train set with dataset that been left out
train = bind_rows(train,Not.Able.To.Split)
dim(train)
train = as.data.frame(train)
test = as.data.frame(test)
validate = as.data.frame(validate)
str(train)
str(CarData)
library(caret)
#getting training response
trainY = train$MSRP
#getting training predictors
trainX = train[,-c(15)]
str(train)
str(trainX)
#getting training predictors
trainX = train[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
str(trainX)
#getting training response
trainY = train$MSRP
#getting training predictors
trainX = train[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
# Doing the same for test
testY = test$MSRP
testX = test[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
fit = knnreg(trainX,trainY,k=3)
plot(testY,predict(fit,testX))
#Try testing testASE
head(fit)
#Try testing testASE
knn.k3.pred = predict(fit,testX)
testASE_KNN_k3 = mean((testY-knn.k3.pred)^2)
sqrt(testASE_KNN_k3)
############# explore optimal k using test ASE ###############
iterations = 100
testASE_List = c()
for(j in 1:iterations){
fit = knnreg(trainX,trainY,k=iterations)
knn.pred = predict(fit,testX)
testASE_loop = mean((testY-knn.pred)^2)
testASE_List[j] = sqrt(testASE_loop)
}
par(mfrow=c(1,1))
plot(1:iterations,testASE_List,type="l",xlab="# of k",ylab="test Root Mean Square Error")
head(testASE_List)
############# explore optimal k using test ASE ###############
iterations = 100
testASE_List = c()
for(j in 1:iterations){
fit = knnreg(trainX,trainY,k=j)
knn.pred = predict(fit,testX)
testASE_loop = mean((testY-knn.pred)^2)
testASE_List[j] = sqrt(testASE_loop)
}
par(mfrow=c(1,1))
plot(1:iterations,testASE_List,type="l",xlab="# of k",ylab="test Root Mean Square Error")
index<-which(testASE_List==min(testASE_List))
index
# seems k=2 gives the best result according to our test ASE
fit = knnreg(trainX,trainY,k=2)
plot(testY,predict(fit,testX))
#Try testing testASE
knn.k2.pred = predict(fit,testX)
testASE_KNN_k2 = mean((testY-knn.k2.pred)^2)
sqrt(testASE_KNN_k2)
# Year-Degree2 didn't get turned on neither did I(Year^3), I(EngineHP^2) did get turned on
# Following also get turned off...
# - Hatchback - Popularity
# Refit the model with predictors
lasso.lm.log = lm(log(MSRP)~.+I(EngineHP^2)-Hatchback-Popularity,data=train)
#####################################################
# Compare Forward vs. Backward on Test set to LASSO #
#####################################################
# Test result
test.result = test$MSRP
# str(test)
test = test[,-15] #delete MSRP for prediction
# LogMSRP with Second Degree EngineHP picked by LASSO test result
lasso.log.pred1 = predict(lasso.lm.log,test)
# Recover the value by exp
lasso.log.pred1 = exp(lasso.log.pred1)
testASE_LASSO_LOG = mean((test.result-lasso.log.pred1)^2)
sqrt(testASE_LASSO_LOG) #24577120
testASE_LASSO_LOG
library(tidyverse)
library(ggplot2)
library(GGally)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Directly import cleaned dataset and start from here
CarData = read.csv("CleanedCarData.csv")
###################################################################################
# Restrict prediction range to over cars under 1 million... To improve precision###
###################################################################################
CarData = CarData %>% filter(MSRP < 1000000)
# Convert factor variables
variables.to.factor = c("Make","Model","EngineFuelType","TransmissionType","DrivenWheels","MarketCategory","VehicleSize","VehicleStyle","Crossover","Diesel","Exotic","Luxury","HighPerformance","FactoryTuner","Performance","FlexFuel","Hatchback","Hybrid","N_A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)
summary(CarData)
# Plot agsint numeric variables
# CarData %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity) %>% ggpairs()
CarData = CarData[,-10] #delete MarketCategory
# Try different way of sampling by Models
######### Try Something else to split data ############
# First 836 are Models that only have 5 observations or less - deleted 6 card over 1 million dollars
ModelList = CarData%>% group_by(Model) %>% mutate(ModelCount = n()) %>% arrange(ModelCount)
#arrange(ModelList,desc(count))%>%print(n = Inf)
# Can only split train/test/validate set on Models that has 6 observations or more
ModelList = ModelList[,-27]
Not.Able.To.Split = ModelList[(1:836),]
Able.To.Split = ModelList[-(1:836),]
# Split Train, test, validate based on able to Train Data...
set.seed(111)
validate.set.index<-sample(1:dim(Able.To.Split)[1],1191,replace=F)
validate = Able.To.Split[validate.set.index,]
remains1 = Able.To.Split[-validate.set.index,]
set.seed(112)
test.index = sample(1:dim(remains1)[1],1191,replace=F)
test = remains1[test.index,]
train = remains1[-test.index,]
# Joining train set with dataset that been left out
train = bind_rows(train,Not.Able.To.Split)
dim(train)
train = as.data.frame(train)
test = as.data.frame(test)
validate = as.data.frame(validate)
str(train)
str(CarData)
# Try Log transformation on MSRP see if it will improve correlations
train$logMSRP = log(train$MSRP)
# It looks like logMSRP has increased correlation with Year but decreased correlation with EngineHP, EngineCylinders
# It's best to run LASSO and choose predictors on both with transformation and without Log transformation in order to identify which
# Model performs better
train = train[,-27]
#str(train)
library(glmnet)
library(car)
# Since we want a easy to interperate model, we don't want to use predictor Make and Model that has too many levels in the model
train = train[,-(1:2)]
#N_A has the highest insignificant P-value delete
log.model8.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+Hybrid+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+Crossover+FactoryTuner+Popularity,data=train)
summary(log.model8.step)
# LASSO and STEPWISE came to slight different Model in terms of predictor and r-squared value.
# LASSO r-squared 0.8426, adjusted r-squared 0.8419
# Stepwise r-squared 0.843, adjusted r-squared 0.8424
#compare test ASE results between stepwise model and LASSO
test = test[,-(1:2)]
testMSRP = test$MSRP # GET real result
test = test[,-13] # Delete MSRP from test
# Calculate stepwise test ASE first
pred.test.step = predict(log.model8.step,test)
# exp values to return to original value
pred.test.step = exp(pred.test.step)
test_ASE_STEP = mean((testMSRP-pred.test.step)^2)
sqrt(test_ASE_STEP) #571362858
test_ASE_STEP
library(tidyverse)
library(ggplot2)
library(GGally)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Directly import cleaned dataset and start from here
CarData = read.csv("CleanedCarData.csv")
###################################################################################
# Restrict prediction range to over cars under 1 million... To improve precision###
###################################################################################
CarData = CarData %>% filter(MSRP < 1000000)
# Convert factor variables
variables.to.factor = c("Make","Model","EngineFuelType","TransmissionType","DrivenWheels","MarketCategory","VehicleSize","VehicleStyle","Crossover","Diesel","Exotic","Luxury","HighPerformance","FactoryTuner","Performance","FlexFuel","Hatchback","Hybrid","N_A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)
summary(CarData)
# Plot agsint numeric variables
# CarData %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity) %>% ggpairs()
CarData = CarData[,-10] #delete MarketCategory
# Try different way of sampling by Models
######### Try Something else to split data ############
# First 836 are Models that only have 5 observations or less - deleted 6 card over 1 million dollars
ModelList = CarData%>% group_by(Model) %>% mutate(ModelCount = n()) %>% arrange(ModelCount)
#arrange(ModelList,desc(count))%>%print(n = Inf)
# Can only split train/test/validate set on Models that has 6 observations or more
ModelList = ModelList[,-27]
Not.Able.To.Split = ModelList[(1:836),]
Able.To.Split = ModelList[-(1:836),]
# Split Train, test, validate based on able to Train Data...
set.seed(111)
validate.set.index<-sample(1:dim(Able.To.Split)[1],1191,replace=F)
validate = Able.To.Split[validate.set.index,]
remains1 = Able.To.Split[-validate.set.index,]
set.seed(112)
test.index = sample(1:dim(remains1)[1],1191,replace=F)
test = remains1[test.index,]
train = remains1[-test.index,]
# Joining train set with dataset that been left out
train = bind_rows(train,Not.Able.To.Split)
dim(train)
train = as.data.frame(train)
test = as.data.frame(test)
validate = as.data.frame(validate)
str(train)
str(CarData)
# Use Forward variable selection method to select possible variables as predictors
########################################
# Try Forward selection model.##########
########################################
library(leaps)
# By looking at this model, it has selected following predictors:
# Make+Model+Year+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+TransmissionType+Exotic+Hatchback
forward.regression = lm(MSRP~Make+Model+Year+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+TransmissionType+Exotic+Hatchback,data=train)
# Predictor for backward elimination method based on lowest BIC value
# Make+Model+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+FactoryTuner+FlexFuel+Exotic+Hatchback
backward.regression = lm(MSRP~Make+Model+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+FactoryTuner+FlexFuel+Exotic+Hatchback,data=train)
################
# In order to look at assumption, need to refit the model based on LASSO selected variables...
# Check coefficients and see what got turn off:
# - Crossover (only one turned off, others are within factor levels that are significant)
################
lasso.lm = lm(MSRP~.-Crossover,data=train)
# Year-Degree2 didn't get turned on neither did I(Year^3), I(EngineHP^2) did get turned on
# Following also get turned off...
# - Hatchback - Popularity
# Refit the model with predictors
lasso.lm.log = lm(log(MSRP)~.+I(EngineHP^2)-Hatchback-Popularity,data=train)
#####################################################
# Compare Forward vs. Backward on Test set to LASSO #
#####################################################
# Test result
test.result = test$MSRP
# str(test)
test = test[,-15] #delete MSRP for prediction
#Forward test results
forward.pred = predict(forward.regression,test)
# See forward test ASE
testMSE_Forward<-mean((test.result-forward.pred)^2)
testMSE_Forward #46054176
sqrt(testMSE_Forward) #46054176
#Backward test results
backward.pred = predict(backward.regression,test)
# See backward test ASE
testMSE_Backward<-mean((test.result-backward.pred)^2)
testMSE_Backward #44935730
sqrt(testMSE_Backward) #44935730
#LASSO test result
lasso.pred2 = predict(lasso.lm,test)
# See LASSO test ASE after refit
testASE_LASSO_2 = mean((test.result-lasso.pred2)^2)
testASE_LASSO_2 #35982124
sqrt(testASE_LASSO_2) #35982124
#getting training response
trainY = train$MSRP
#getting training predictors
trainX = train[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
# Doing the same for test
testY = test$MSRP
testX = test[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
library(tidyverse)
library(ggplot2)
library(GGally)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Directly import cleaned dataset and start from here
CarData = read.csv("CleanedCarData.csv")
###################################################################################
# Restrict prediction range to over cars under 1 million... To improve precision###
###################################################################################
CarData = CarData %>% filter(MSRP < 1000000)
# Convert factor variables
variables.to.factor = c("Make","Model","EngineFuelType","TransmissionType","DrivenWheels","MarketCategory","VehicleSize","VehicleStyle","Crossover","Diesel","Exotic","Luxury","HighPerformance","FactoryTuner","Performance","FlexFuel","Hatchback","Hybrid","N_A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)
summary(CarData)
# Plot agsint numeric variables
# CarData %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity) %>% ggpairs()
CarData = CarData[,-10] #delete MarketCategory
# Try different way of sampling by Models
######### Try Something else to split data ############
# First 836 are Models that only have 5 observations or less - deleted 6 card over 1 million dollars
ModelList = CarData%>% group_by(Model) %>% mutate(ModelCount = n()) %>% arrange(ModelCount)
#arrange(ModelList,desc(count))%>%print(n = Inf)
# Can only split train/test/validate set on Models that has 6 observations or more
ModelList = ModelList[,-27]
Not.Able.To.Split = ModelList[(1:836),]
Able.To.Split = ModelList[-(1:836),]
# Split Train, test, validate based on able to Train Data...
set.seed(111)
validate.set.index<-sample(1:dim(Able.To.Split)[1],1191,replace=F)
validate = Able.To.Split[validate.set.index,]
remains1 = Able.To.Split[-validate.set.index,]
set.seed(112)
test.index = sample(1:dim(remains1)[1],1191,replace=F)
test = remains1[test.index,]
train = remains1[-test.index,]
# Joining train set with dataset that been left out
train = bind_rows(train,Not.Able.To.Split)
dim(train)
train = as.data.frame(train)
test = as.data.frame(test)
validate = as.data.frame(validate)
str(train)
str(CarData)
#getting training response
trainY = train$MSRP
#getting training predictors
trainX = train[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
# Doing the same for test
testY = test$MSRP
testX = test[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
fit = knnreg(trainX,trainY,k=3)
plot(testY,predict(fit,testX))
# seems k=2 gives the best result according to our test ASE
fit = knnreg(trainX,trainY,k=2)
plot(testY,predict(fit,testX))
#Try testing testASE
knn.k2.pred = predict(fit,testX)
testASE_KNN_k2 = mean((testY-knn.k2.pred)^2)
sqrt(testASE_KNN_k2)

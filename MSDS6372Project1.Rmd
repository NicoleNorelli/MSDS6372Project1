---
title: "MSDS6372Project1"
author: "Nicole Norelli, Alex Gilbert & Mingyang Nick YU"
date: "1/20/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Automible MSRP Analysis and Prediction

**Data Import and Cleaning...**
```{r dataINC}
library(tidyverse)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Read in data under variable CarData
CarData = read.csv("data1.csv")
# Fixing three empty values in CarData$Engine.Fuel.Type, after research they are regular unleaded
CarData$Engine.Fuel.Type = ifelse(CarData$Engine.Fuel.Type=="","regular unleaded",CarData$Engine.Fuel.Type)
# Fixing Engine Cylinders to 0 -- Mazda RX or Electrical Vehicle
CarData$Engine.Cylinders = ifelse(is.na(CarData$Engine.Cylinders),0,CarData$Engine.Cylinders)
# Fixing Tesla Model S with Number.of.Doors missing
CarData$Number.of.Doors = ifelse(CarData$Make=="Tesla"&is.na(CarData$Number.of.Doors),4,CarData$Number.of.Doors)
# Fixing Tesla HP with mean HP found online of 510
#CarData$Number.of.Doors = ifelse(CarData$Make=="Tesla"&is.na(CarData$Number.of.Doors),4,CarData$Number.of.Doors)
# Fixing Ferrari FF 2013 Number.of.Doors to 2 -- Google research
CarData$Number.of.Doors = ifelse(CarData$Make=="Ferrari"&is.na(CarData$Number.of.Doors),2,CarData$Number.of.Doors)
# Fixing FIAT 500e HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="FIAT"&is.na(CarData$Engine.HP),111,CarData$Engine.HP)
# Fixing Lincoln Continental HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Lincoln"&is.na(CarData$Engine.HP),345,CarData$Engine.HP)
# Fixing Ford Escape HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Ford"&is.na(CarData$Engine.HP),210,CarData$Engine.HP)
# Fixing Honda Fit EV HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Honda"&is.na(CarData$Engine.HP),123,CarData$Engine.HP)
# Fixing Mitsubishi i-MiEV HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Mitsubishi"&is.na(CarData$Engine.HP),66,CarData$Engine.HP)
# Fixing Chevrolet  Impala HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Chevrolet"&is.na(CarData$Engine.HP),305,CarData$Engine.HP)
# Fixing Nissan Leaf HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Nissan"&is.na(CarData$Engine.HP),177,CarData$Engine.HP)
# Fixing Tesla Model S HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Tesla"&is.na(CarData$Engine.HP),503,CarData$Engine.HP)
# Fixing Mercedes-Benz M-Class S HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Mercedes-Benz"&is.na(CarData$Engine.HP),350,CarData$Engine.HP) 
# Fixing Toyota RAV4 HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Toyota"&is.na(CarData$Engine.HP),203,CarData$Engine.HP) 
# Fixing Kia Soul EV HP NA value based on research on mean Horsepower
CarData$Engine.HP = ifelse(CarData$Make=="Kia"&is.na(CarData$Engine.HP),109,CarData$Engine.HP) 

#Market.Category: Crossover,Diesel,Exotic,Luxury,High-Performance,Factory Tuner,Performance,Flex Fuel,Hatchback,Hybrid,N/A (Note: Performance column will be handled individually becuase of presence of High-Performance)
marketCat = c("Crossover","Diesel","Exotic","Luxury","High-Performance","Factory Tuner","Flex Fuel","Hatchback","Hybrid","N/A")
marketCat = data.frame(marketCat)

# Add each Market Category as column
CarData['Crossover'] <- NA
CarData['Diesel'] <- NA
CarData['Exotic'] <- NA
CarData['Luxury'] <- NA
CarData['High-Performance'] <- NA
CarData['Factory Tuner'] <- NA
CarData['Performance'] <- NA
CarData['Flex Fuel'] <- NA
CarData['Hatchback'] <- NA
CarData['Hybrid'] <- NA
CarData['N/A'] <- NA

str(CarData)
# Use For loop to fill in Yes/No to each Market Category column
for(j in 1:dim(marketCat)[1]){
  CarData[marketCat[j,1]] = ifelse(grepl(marketCat[j,1],CarData$Market.Category),"Yes","No")
}
# Performance is being handled individually...
CarData$Performance = ifelse(grepl("Performance",CarData$Market.Category)&(!grepl("High-Performance",CarData$Market.Category)),"Yes","No")
# Flex Fuel column if EngineFuelType has flex-fuel
CarData$`Flex Fuel` = ifelse(grepl("flex-fuel",CarData$Engine.Fuel.Type)&CarData$`Flex Fuel`=="No","Yes",CarData$`Flex Fuel`)

# Convert factor variables
variables.to.factor = c("Make","Model","Engine.Fuel.Type","Transmission.Type","Driven_Wheels","Market.Category","Vehicle.Size","Vehicle.Style","Crossover","Diesel","Exotic","Luxury","High-Performance","Factory Tuner","Performance","Flex Fuel","Hatchback","Hybrid","N/A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)

# Adjust column names - get ride of - and space in the column names to make analysis easier
# Also make column names more uniform
CarData = CarData %>%
  rename(
    EngineFuelType = Engine.Fuel.Type,
    EngineHP = Engine.HP,
    EngineCylinders = Engine.Cylinders,
    TransmissionType = Transmission.Type,
    DrivenWheels = Driven_Wheels,
    NumberOfDoors = Number.of.Doors,
    MarketCategory = Market.Category,
    VehicleSize = Vehicle.Size,
    VehicleStyle = Vehicle.Style,
    HighwayMPG = highway.MPG,
    CityMPG = city.mpg,
    HighPerformance = `High-Performance`,
    FactoryTuner = `Factory Tuner`,
    FlexFuel = `Flex Fuel`,
    N_A = `N/A`
  )
# Look at HighwayMPG outlier identified by Nicole
CarData %>% filter(HighwayMPG==354)
# Change observation HighwayMPG 354 to 34
CarData$HighwayMPG = ifelse(CarData$HighwayMPG==354,34,CarData$HighwayMPG)

# Look at summary of data
str(CarData)
# Look at missing Data if any
# missingData = CarData[rowSums(is.na(CarData)) > 0,]
# missingData
# dim(missingData)
write.csv(CarData,"CleanedCarData.csv",row.names = FALSE)

```

# Start Here... Load in cleanedData, delete over 1 million dollar cars
## split dataset into train/test/validate sets with set seed number
### Models that only have 5 observations will all end up in train set
```{r}
library(tidyverse)
library(ggplot2)
library(GGally)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Directly import cleaned dataset and start from here
CarData = read.csv("CleanedCarData.csv")
###################################################################################
# Restrict prediction range to over cars under 1 million... To improve precision###
###################################################################################
CarData = CarData %>% filter(MSRP < 1000000)
# Convert factor variables
variables.to.factor = c("Make","Model","EngineFuelType","TransmissionType","DrivenWheels","MarketCategory","VehicleSize","VehicleStyle","Crossover","Diesel","Exotic","Luxury","HighPerformance","FactoryTuner","Performance","FlexFuel","Hatchback","Hybrid","N_A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)
summary(CarData)
# Plot agsint numeric variables
# CarData %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity) %>% ggpairs()
CarData = CarData[,-10] #delete MarketCategory
# Try different way of sampling by Models

######### Try Something else to split data ############
# First 836 are Models that only have 5 observations or less - deleted 6 card over 1 million dollars
ModelList = CarData%>% group_by(Model) %>% mutate(ModelCount = n()) %>% arrange(ModelCount)
#arrange(ModelList,desc(count))%>%print(n = Inf)
# Can only split train/test/validate set on Models that has 6 observations or more
ModelList = ModelList[,-27]
Not.Able.To.Split = ModelList[(1:836),]
Able.To.Split = ModelList[-(1:836),]

# Split Train, test, validate based on able to Train Data...
set.seed(111)
validate.set.index<-sample(1:dim(Able.To.Split)[1],1191,replace=F)
validate = Able.To.Split[validate.set.index,]
remains1 = Able.To.Split[-validate.set.index,]
set.seed(112)
test.index = sample(1:dim(remains1)[1],1191,replace=F)
test = remains1[test.index,]
train = remains1[-test.index,]

# Joining train set with dataset that been left out
train = bind_rows(train,Not.Able.To.Split)

dim(train)
train = as.data.frame(train)
test = as.data.frame(test)
validate = as.data.frame(validate)
str(train)
str(CarData)
```

#### Objecive 1
We are trying to analyse the importance of the "Popularity" variable. While the details of this variable is vague, it was created from social media, and the "higher ups" are curious how much general popularity can play a role in the retail price of a vehicle.

This model need to be highly interpretable. We need to provide interpretation of the regression coefficients of the final model including hypothesis testing, interpretation of regression coefficients, and confidence intervals.

```{r}
# Explore numerical variables
train %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity)%>%ggpairs()
# Try Log transformation on MSRP see if it will improve correlations
train$logMSRP = log(train$MSRP)
train %>% select(logMSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity)%>%ggpairs()
# It looks like logMSRP has increased correlation with Year but decreased correlation with EngineHP, EngineCylinders
# It's best to run LASSO and choose predictors on both with transformation and without Log transformation in order to identify which
# Model performs better
train = train[,-27]
#str(train)
library(glmnet)
library(car)
# Since we want a easy to interperate model, we don't want to use predictor Make and Model that has too many levels in the model
train = train[,-(1:2)]
str(train)
#Dummy code categorical predictor variables
x <- model.matrix(MSRP~.,train)[,-1]
y <- log(train$MSRP)
set.seed(123) # Need a seed number to keep same results for LASSO
cv.out=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
par(mfrow=c(1,1))
plot(cv.out)
# Look at coefficients
coef(cv.out, cv.out$lambda.min)
# Seems like LASSO has selected all predictors, only few levels within EngineFuel, TransmissionType, VehicleStyle got turned off
# Build model with predictors LASSO selected
log.model1 = lm(log(MSRP)~.,data=train)
# Check VIF
summary(log.model1)
# TransmissionType and Hatchback provides NA on summary statistic, try remove them as predictors
log.model2 = lm(log(MSRP)~.- TransmissionType - Hatchback,data=train)
summary(log.model2)
# Look at VIF
vif(log.model2)[,3]^2
# CityMPG has really high VIF remove it from model
log.model3 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG,data=train)
# Look at VIF
vif(log.model3)[,3]^2
# NumberOfDoors has really high VIF remove from model
log.model4 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG - NumberOfDoors,data=train)
# Look at VIF
vif(log.model4)[,3]^2
# HighwayMPG still have over 10 VIF, remove from model
log.model5 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG - NumberOfDoors - HighwayMPG,data=train)
vif(log.model5)[,3]^2
summary(log.model5)
# HighPerformance has the least statistical significance - delete
log.model6 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG - NumberOfDoors - HighwayMPG - HighPerformance, data=train)
vif(log.model6)[,3]^2
summary(log.model6)
# Diesel has the least statistical significance - delete
log.model6 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG - NumberOfDoors - HighwayMPG - HighPerformance - Diesel, data=train)
vif(log.model6)[,3]^2
summary(log.model6)
# N_A has the least statistical significance - delete
log.model6 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG - NumberOfDoors - HighwayMPG - HighPerformance - Diesel - N_A, data=train)
vif(log.model6)[,3]^2
summary(log.model6)
# Performance is still not significant, remove from model
log.model7 = lm(log(MSRP)~.- TransmissionType - Hatchback - CityMPG - NumberOfDoors - HighwayMPG - HighPerformance - Diesel - N_A - Performance, data=train)
vif(log.model7)[,3]^2
summary(log.model7)
# Model 7 is a highly interpretable model with decent R-squared.

par(mfrow=c(2,2))
plot(log.model7)
library(olsrr)
ols_plot_cooksd_bar(log.model7)
ols_plot_resid_stand(log.model7)
# Residual looks okay~
# Now try MSRP without log transformation

#Dummy code categorical predictor variables
x1 <- model.matrix(MSRP~.,train)[,-1]
y1 <- train$MSRP
set.seed(123) # Need a seed number to keep same results for LASSO
cv.out1=cv.glmnet(x1,y1,alpha=1) #alpha=1 performs LASSO
par(mfrow=c(1,1))
plot(cv.out1)
# Look at coefficients
coef(cv.out1, cv.out1$lambda.min)
# Again, all predictors are selected, only few levels are turned off
regular.model1 = lm(MSRP~.,data=train)
summary(regular.model1)
# Delete Hatchback & TransmissionType... NA on summary table
regular.model2 = lm(MSRP~.-Hatchback-TransmissionType,data=train)
vif(regular.model2)[,3]^2
# remove CityMPG - highest VIF, larger than 29
regular.model3 = lm(MSRP~.-Hatchback-TransmissionType-CityMPG,data=train)
vif(regular.model3)[,3]^2
# remove NumberOfDoors
regular.model4 = lm(MSRP~.-Hatchback-TransmissionType-CityMPG-NumberOfDoors,data=train)
vif(regular.model4)[,3]^2
# HighwayMPG still over 10
regular.model5 = lm(MSRP~.-Hatchback-TransmissionType-CityMPG-NumberOfDoors-HighwayMPG,data=train)
vif(regular.model5)[,3]^2
summary(regular.model5)
# FlexFuel has the highest P value in terms of significance - delete
regular.model6 = lm(MSRP~.-Hatchback-TransmissionType-CityMPG-NumberOfDoors-HighwayMPG-FlexFuel,data=train)
vif(regular.model6)[,3]^2
summary(regular.model6)
#Diesel is high in p-value delete
regular.model7 = lm(MSRP~.-Hatchback-TransmissionType-CityMPG-NumberOfDoors-HighwayMPG-FlexFuel-Diesel,data=train)
vif(regular.model7)[,3]^2
summary(regular.model7)
par(mfrow=c(2,2))
plot(regular.model1) # Residual plot doesn't look as well as log(MSRP) residual so tranformation is necessary.
ols_plot_cooksd_bar(regular.model1)
ols_plot_resid_stand(regular.model1)

#############################################################################
# By comparison Constant variance looks a lot better with the log(MSRP)...###
# Since the assumption works best with this, next check with stepwise method to see what predictors will be selected
stepwise.model1 =lm(log(MSRP)~.,data=train)
ols_step_both_aic(stepwise.model1)
# By Using StepwiseAIC variable selection method, the following predictors are selected
# Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+HighwayMPG+Hybrid+TransmissionType+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+NumberOfDoors+Crossover+FactoryTuner+Popularity+CityMPG+N_A
log.model2.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+HighwayMPG+Hybrid+TransmissionType+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+NumberOfDoors+Crossover+FactoryTuner+Popularity+CityMPG+N_A,data=train)
summary(log.model2.step)
# TransmissionType has NA need to be deleted
log.model3.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+HighwayMPG+Hybrid+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+NumberOfDoors+Crossover+FactoryTuner+Popularity+CityMPG+N_A,data=train)
summary(log.model3.step)
vif(log.model3.step)[,3]^2
# CityMPG has the highest VIF - delete
log.model4.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+HighwayMPG+Hybrid+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+NumberOfDoors+Crossover+FactoryTuner+Popularity+N_A,data=train)
vif(log.model4.step)[,3]^2
# NumberOfDoors highest VIF - delete
log.model5.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+HighwayMPG+Hybrid+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+Crossover+FactoryTuner+Popularity+N_A,data=train)
vif(log.model5.step)[,3]^2
# HighwayMPG still over 10 - delete
log.model5.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+Hybrid+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+Crossover+FactoryTuner+Popularity+N_A,data=train)
vif(log.model5.step)[,3]^2
summary(log.model5.step)
#N_A has the highest insignificant P-value delete
log.model8.step = lm(log(MSRP)~Year+EngineHP+Exotic+EngineFuelType+VehicleStyle+Hybrid+EngineCylinders+Luxury+VehicleSize+DrivenWheels+FlexFuel+Crossover+FactoryTuner+Popularity,data=train)
summary(log.model8.step)

par(mfrow=c(2,2))
plot(log.model8.step)
ols_plot_cooksd_bar(log.model8.step)
ols_plot_resid_stand(log.model8.step)

# LASSO and STEPWISE came to slight different Model in terms of predictor and r-squared value.
# LASSO r-squared 0.8426, adjusted r-squared 0.8419
# Stepwise r-squared 0.843, adjusted r-squared 0.8424
#compare test ASE results between stepwise model and LASSO
test = test[,-(1:2)]
testMSRP = test$MSRP # GET real result 
test = test[,-13] # Delete MSRP from test 
# Calculate stepwise test ASE first
pred.test.step = predict(log.model8.step,test)
# exp values to return to original value
pred.test.step = exp(pred.test.step)
test_ASE_STEP = mean((testMSRP-pred.test.step)^2)
sqrt(test_ASE_STEP) #test RMSE = 23903.2

#Calculate LASSO test ASE
pred.test.lasso = predict(log.model7,test)
pred.test.lasso = exp(pred.test.lasso)
test_ASE_LASSO = mean((testMSRP-pred.test.lasso)^2)
sqrt(test_ASE_LASSO) ##test RMSE = 23903.2

# By comparison, Stepwise model workflow provided the best model in terms of r-squared, adjusted r-squared and test ASE.
# Move forward with the analysis with log.model8.step
```

# Note: Rerun the code chunk for clean train/test/validate datasets - altered in Objective 1
#### Objective 2 start without Log transformation - since there are so many categorical variables

```{r}
# Use Forward variable selection method to select possible variables as predictors
########################################
# Try Forward selection model.##########
########################################
library(leaps)
reg.fwd=regsubsets(MSRP~.,data=train,method="forward",nvmax=963)
par(mfrow=c(1,3))
bics<-summary(reg.fwd)$bic
plot(1:964,bics,type="l",ylab="BIC",xlab="# of predictors")
index<-which(bics==min(bics))
points(index,bics[index],col="red",pch=10)

adjr2<-summary(reg.fwd)$adjr2
plot(1:964,adjr2,type="l",ylab="Adjusted R-squared",xlab="# of predictors")
index<-which(adjr2==max(adjr2))
points(index,adjr2[index],col="red",pch=10)

rss<-summary(reg.fwd)$rss
plot(1:964,rss,type="l",ylab="train RSS",xlab="# of predictors")
index<-which(rss==min(rss))
points(index,rss[index],col="red",pch=10)

# how many predictors gives the best BIC?
which(bics==min(bics))
coef(reg.fwd,349)
# By looking at this model, it has selected following predictors:
# Make+Model+Year+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+TransmissionType+Exotic+Hatchback
forward.regression = lm(MSRP~Make+Model+Year+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+TransmissionType+Exotic+Hatchback,data=train)
summary(forward.regression)
# This model has higher adjusted R-squared compared to the Log transformed model
par(mfrow=c(2,2))
plot(forward.regression)
library(olsrr)
ols_plot_cooksd_bar(forward.regression)
ols_plot_resid_stand(forward.regression)
# Cook's D plot looks okay 
# Residual plot... ???


########################################
# Try Backward elimination model.#######
########################################
reg.bwd=regsubsets(MSRP~.,data=train,method="backward",nvmax=963)
par(mfrow=c(1,3))
bics<-summary(reg.bwd)$bic
plot(1:964,bics,type="l",ylab="BIC",xlab="# of predictors")
index<-which(bics==min(bics))
points(index,bics[index],col="red",pch=10)

adjr2<-summary(reg.bwd)$adjr2
plot(1:964,adjr2,type="l",ylab="Adjusted R-squared",xlab="# of predictors")
index<-which(adjr2==max(adjr2))
points(index,adjr2[index],col="red",pch=10)

rss<-summary(reg.bwd)$rss
plot(1:964,rss,type="l",ylab="train RSS",xlab="# of predictors")
index<-which(rss==min(rss))
points(index,rss[index],col="red",pch=10)

# how many predictors gives the best BIC?
which(bics==min(bics))
coef(reg.bwd,410)
# Predictor for backward elimination method based on lowest BIC value
# Make+Model+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+FactoryTuner+FlexFuel+Exotic+Hatchback
backward.regression = lm(MSRP~Make+Model+EngineFuelType+NumberOfDoors+VehicleSize+VehicleStyle+CityMPG+Luxury+FactoryTuner+FlexFuel+Exotic+Hatchback,data=train)
summary(backward.regression)
# Forward select has higher adjusted R-squared compared to backward method
par(mfrow=c(2,2))
plot(backward.regression)

ols_plot_cooksd_bar(backward.regression)
ols_plot_resid_stand(backward.regression)
#Observation 3748, 9152 and 9153 seem to have problem on the residual plot - Same as forward selection


########################################
# Try LASSO variable selection #########
########################################
library(glmnet)
#Dummy code categorical predictor variables
x <- model.matrix(MSRP~.,train)[,-1]
y <- train$MSRP
set.seed(123) # Need a seed number to keep same results for LASSO
cv.out=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
par(mfrow=c(1,1))
plot(cv.out)
# Look at the coefficient for best lambda
# Make+Model+Year+EngineFuelType+EngineHP+EngineCylinders+TransmissionType+DrivenWheels+NumberOfDoors+VehicleSize+VehicleStyle+HighwayMPG+CityMPG+Popularity+Crossover+Diesel+Exotic+Luxury+HighPerformance+FactoryTurner+Performance+FlexFuel+Hatchback+Hybrid+Yes+N_A
# Lasso turned off some predictors in Make, Model,VehicleStyle... In order to check assumptions, we need to use lm model with all the predictors
# Although this won't imitate the Lasso model perfectly though.
coefficients = coef(cv.out, cv.out$lambda.min)
head(coefficients)
# Compute the final lasso model
lasso.model = glmnet(x,y,alpha = 1,lambda = cv.out$lambda.min)
#Dummy code test set to see performance compare to other methods
xtest<-model.matrix(MSRP~.,test)[,-1]
ytest<-test$MSRP #36302210

# See prediction
lasso.pred=predict(lasso.model ,newx=xtest)
# See test ASE
testMSE_LASSO<-mean((ytest-lasso.pred)^2)
testMSE_LASSO
################
# In order to look at assumption, need to refit the model based on LASSO selected variables...
# Check coefficients and see what got turn off:
# - Crossover (only one turned off, others are within factor levels that are significant)
################
lasso.lm = lm(MSRP~.-Crossover,data=train)
summary(lasso.lm)
# Check Assumptions
par(mfrow=c(2,2))
plot(lasso.lm)
library(olsrr)
ols_plot_cooksd_bar(lasso.lm)
ols_plot_resid_stand(lasso.lm)


##################################################################################
# Try Log(MSRP vs cubic Year & Second degree EngineHP variable selection #########
##################################################################################

# Above are findings during EDA... connections to logMSRP
engineHP.lm = lm(log(MSRP)~EngineHP,data=train)
ols_plot_resid_stand(engineHP.lm)
# Looks like Second degree might help
engineHP.lm2 = lm(log(MSRP)~EngineHP+I(EngineHP^2),data=train)
ols_plot_resid_stand(engineHP.lm2)

#Without transformation
engineHP.lm = lm(MSRP~EngineHP,data=train)
ols_plot_resid_stand(engineHP.lm)
# Looks like Second degree might help, and MSRP looks better than log(MSRP)
engineHP.lm2 = lm(MSRP~EngineHP+I(EngineHP^2),data=train)
ols_plot_resid_stand(engineHP.lm2)

# Try year
year.lm = lm(log(MSRP)~Year,data=train)
ols_plot_resid_stand(year.lm)
# Try Second Degree Year
year.lm2 = lm(log(MSRP)~Year+I(Year^2),data=train)
ols_plot_resid_stand(year.lm2)
# Try Third Degree Year
year.lm3 = lm(log(MSRP)~Year+I(Year^2)+I(Year^3),data=train)
ols_plot_resid_stand(year.lm3)
#Try regular MSRP
# Try year
year.lm = lm(MSRP~Year,data=train)
ols_plot_resid_stand(year.lm)
# Try Second Degree Year
year.lm2 = lm(MSRP~Year+I(Year^2),data=train)
ols_plot_resid_stand(year.lm2)
# Try Third Degree Year
year.lm3 = lm(MSRP~Year+I(Year^2)+I(Year^3),data=train)
ols_plot_resid_stand(year.lm3)
############### Looks like LogMSRP vs year degree 3 helps
############### Looks like LogMSRP vs EngineHP degree 2 helps
# Reselect variables with LASSO
#Dummy code categorical predictor variables
x <- model.matrix(log(MSRP)~.+I(EngineHP^2)+I(Year^2)+I(Year^3),train)[,-1]
y <- log(train$MSRP)
set.seed(123) # Need a seed number to keep same results for LASSO
cv.out2=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
par(mfrow=c(1,1))
plot(cv.out2)
coef(cv.out2, cv.out2$lambda.min)
# Year-Degree2 didn't get turned on neither did I(Year^3), I(EngineHP^2) did get turned on
# Following also get turned off...
# - Hatchback - Popularity 
# Refit the model with predictors
lasso.lm.log = lm(log(MSRP)~.+I(EngineHP^2)-Hatchback-Popularity,data=train)
summary(lasso.lm.log) # R-Squared and Adjusted R-squared is slightly lower compared to regular MSRP using LASSO
# Check Assumptions
par(mfrow=c(2,2))
plot(lasso.lm.log)
library(olsrr)
ols_plot_cooksd_bar(lasso.lm.log)
ols_plot_resid_stand(lasso.lm.log)
#Residual looks okay... check test ASE below

#####################################################
# Compare Forward vs. Backward on Test set to LASSO #
#####################################################
# Test result
test.result = test$MSRP
# str(test)
test = test[,-15] #delete MSRP for prediction
#Forward test results
forward.pred = predict(forward.regression,test)
# See forward test ASE
testMSE_Forward<-mean((test.result-forward.pred)^2)
testMSE_Forward #46054176

#Backward test results
backward.pred = predict(backward.regression,test)
# See backward test ASE
testMSE_Backward<-mean((test.result-backward.pred)^2)
testMSE_Backward #44935730

#LASSO test result
lasso.pred2 = predict(lasso.lm,test)
# See LASSO test ASE after refit
testASE_LASSO_2 = mean((test.result-lasso.pred2)^2)
testASE_LASSO_2 #35982124

# LogMSRP with Second Degree EngineHP picked by LASSO test result
lasso.log.pred1 = predict(lasso.lm.log,test)
# Recover the value by exp
lasso.log.pred1 = exp(lasso.log.pred1)
testASE_LASSO_LOG = mean((test.result-lasso.log.pred1)^2)
sqrt(testASE_LASSO_LOG) #test RMSE = 4957.532

```

# Note: Rerun the code chunk for clean train/test/validate datasets
#### Objective 2 KNN Regression
KNN Regression is a non-parametric machine learning approach, it first identifies the K training observations that are closest to X0, it then estimates the response using the average of all the training response identified. The optimal value for K will depend on the bias-variance trade off. A small K provides the most flexible fit, which will have low bias but high variance. This variance is due to the fact that the prediction in a given region is entirely dependent on just one observation. In contrast, larger values of K provide a smoother and less variable fit; the prediction in a region is an average of several points, and so changing one observation has smaller effect. However, the smoothing may cause bias by masking some of the structure in the response. -- (ISLR Seventh Edition) Note: KNN regression can only handles numerical variables.


```{r}
library(caret)
############################################################
#testing KNN regression - only handles numeric variables####
############################################################

#getting training response
trainY = train$MSRP
#getting training predictors
trainX = train[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]
# Doing the same for test
testY = test$MSRP
testX = test[,-c(1,2,4,7,8,10,11,15,16,17,18,19,20,21,22,23,24,25,26)]

fit = knnreg(trainX,trainY,k=3)
plot(testY,predict(fit,testX))
#Try testing testASE
knn.k3.pred = predict(fit,testX)
testASE_KNN_k3 = mean((testY-knn.k3.pred)^2)
sqrt(testASE_KNN_k3)

############# explore optimal k using test ASE ###############
iterations = 100
testASE_List = c()
for(j in 1:iterations){
  fit = knnreg(trainX,trainY,k=j)
  knn.pred = predict(fit,testX)
  testASE_loop = mean((testY-knn.pred)^2)
  testASE_List[j] = sqrt(testASE_loop)
}
par(mfrow=c(1,1))
plot(1:iterations,testASE_List,type="l",xlab="# of k",ylab="test Root Mean Square Error")
index<-which(testASE_List==min(testASE_List))
index

# seems k=2 gives the best result according to our test ASE
fit = knnreg(trainX,trainY,k=2)
plot(testY,predict(fit,testX))
#Try testing testASE
knn.k2.pred = predict(fit,testX)
testASE_KNN_k2 = mean((testY-knn.k2.pred)^2)
sqrt(testASE_KNN_k2)

```











